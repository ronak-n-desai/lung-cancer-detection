{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom glob import glob\n \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport time \nimport cv2\nimport gc\nimport os \n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:21.734680Z","iopub.execute_input":"2024-08-25T14:33:21.734962Z","iopub.status.idle":"2024-08-25T14:33:28.653136Z","shell.execute_reply.started":"2024-08-25T14:33:21.734935Z","shell.execute_reply":"2024-08-25T14:33:28.652138Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataset_path = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/'\nprint(os.listdir(dataset_path))","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:28.654721Z","iopub.execute_input":"2024-08-25T14:33:28.655273Z","iopub.status.idle":"2024-08-25T14:33:28.676855Z","shell.execute_reply.started":"2024-08-25T14:33:28.655246Z","shell.execute_reply":"2024-08-25T14:33:28.675989Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['lung_aca', 'lung_scc', 'lung_n']\n","output_type":"stream"}]},{"cell_type":"code","source":"classes = os.listdir(dataset_path)\nclasses","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:28.682225Z","iopub.execute_input":"2024-08-25T14:33:28.682853Z","iopub.status.idle":"2024-08-25T14:33:28.689778Z","shell.execute_reply.started":"2024-08-25T14:33:28.682823Z","shell.execute_reply":"2024-08-25T14:33:28.688888Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['lung_aca', 'lung_scc', 'lung_n']"},"metadata":{}}]},{"cell_type":"code","source":"IMG_SIZE = 256\nSPLIT = 0.2\nEPOCHS = 10\nBATCH_SIZE = 64\nlearning_rate = 0.001\nnum_epochs = 20\nNODE = np.int_(IMG_SIZE / 4)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:28.690949Z","iopub.execute_input":"2024-08-25T14:33:28.691260Z","iopub.status.idle":"2024-08-25T14:33:28.696363Z","shell.execute_reply.started":"2024-08-25T14:33:28.691231Z","shell.execute_reply":"2024-08-25T14:33:28.695528Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\nfrom torch.utils.data import DataLoader\n\n# Define transformations (e.g., resizing, normalization)\ntransform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize images to 224x224\n    transforms.ToTensor(),  # Convert PIL image to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n])\n\n# Load dataset from local directory\ndata_dir = 'C:/Users/abdun/Lung_cancer/lung_colon_image_set/lung_image_sets'\ndataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n\n# Create DataLoader\n#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n# Load dataset\n\n\ngenerator1 = torch.Generator().manual_seed(42)\ntrain_set, val_set = torch.utils.data.random_split(dataset, [0.8, 0.2], generator=generator1 )\n\n# Create DataLoader\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True)\ntest_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True,)\n\nprint(len(train_set))\nimg, label = dataset[10]\nprint(img.shape)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-25T14:33:28.697506Z","iopub.execute_input":"2024-08-25T14:33:28.697758Z","iopub.status.idle":"2024-08-25T14:33:47.762450Z","shell.execute_reply.started":"2024-08-25T14:33:28.697738Z","shell.execute_reply":"2024-08-25T14:33:47.761524Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"12000\ntorch.Size([3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:47.763714Z","iopub.execute_input":"2024-08-25T14:33:47.764026Z","iopub.status.idle":"2024-08-25T14:33:47.791246Z","shell.execute_reply.started":"2024-08-25T14:33:47.763990Z","shell.execute_reply":"2024-08-25T14:33:47.790219Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Creating a CNN class\nclass NetWidth(nn.Module):\n  def __init__(self, n_chanl = 32):\n    super().__init__()\n    self.conv1 = nn.Conv2d(3, n_chanl, kernel_size=3, padding=1)\n    self.act1 = nn.Tanh()\n    self.pool1 = nn.MaxPool2d(2)\n    self.conv2 = nn.Conv2d(n_chanl, n_chanl // 2, kernel_size=3, padding=1)\n    self.act2 = nn.Tanh()\n    self.pool2 = nn.MaxPool2d(2)\n    self.fc1 = nn.Linear(n_chanl * NODE * NODE // 2, 64) # NODE is (IMG_SIZE)devided by (2*2) from the max pool.\n    self.act3 = nn.ReLU()\n    self.fc3 = nn.Linear(64, 64)\n    self.fc4 = nn.Linear(64, 32)\n    self.fc2 = nn.Linear(32, 3)\n  def forward(self, x):\n    out = self.pool1(self.act3(self.conv1(x)))\n    out = self.pool2(self.act3(self.conv2(out)))\n    out = out.view(out.size(0), -1)\n    out = self.act3(self.fc1(out))\n    out = self.act3(self.fc3(out))\n    out = self.act3(self.fc4(out))\n    out = self.fc2(out)\n    return out\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:47.792685Z","iopub.execute_input":"2024-08-25T14:33:47.793032Z","iopub.status.idle":"2024-08-25T14:33:47.804985Z","shell.execute_reply.started":"2024-08-25T14:33:47.792999Z","shell.execute_reply":"2024-08-25T14:33:47.804152Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = NetWidth()\nmodel = nn.DataParallel(model)\nmodel = model.to(device=device)\n\n# Set Loss function with criterion\nloss_fn = nn.CrossEntropyLoss()\n\n# Set optimizer with optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.01, momentum = 0.5)  \n\ntotal_step = len(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:47.805937Z","iopub.execute_input":"2024-08-25T14:33:47.806213Z","iopub.status.idle":"2024-08-25T14:33:48.004685Z","shell.execute_reply.started":"2024-08-25T14:33:47.806183Z","shell.execute_reply":"2024-08-25T14:33:48.003794Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"epoch_list = []\ntime_list = []\ntrain_lost_list = []\ntrain_acc_list = []\nval_acc_list =[]","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:48.008628Z","iopub.execute_input":"2024-08-25T14:33:48.009254Z","iopub.status.idle":"2024-08-25T14:33:48.013903Z","shell.execute_reply.started":"2024-08-25T14:33:48.009217Z","shell.execute_reply":"2024-08-25T14:33:48.012911Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ndef training_loop(n_epochs, optimizer, model, loss_fn, train_loader, inter_test, dump_csv):\n   \n  model.train()\n  for epoch in range(1, n_epochs + 1):\n      loss_train = 0.0\n      for imgs, labels in train_loader:\n            imgs = imgs.to(device=device)\n            labels = labels.to(device=device)\n            #model = model.to(device=device)\n            outputs = model(imgs)\n            loss = loss_fn(outputs, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            loss_train += loss.item()\n\n      epoch_time = time.time() - start_time\n      epoch_time = f\"{epoch_time:.2f}\"\n      if epoch == 1 or epoch  != 0:\n         print('{} Epoch {}, Training loss {}'.format(\n             epoch_time, epoch,\n             loss_train / len(train_loader)))\n      if(inter_test == 1 or epoch > 20 or epoch % 5 ==0):  \n        acc_train, acc_val = validate(model, train_loader, test_loader)\n      if(dump_csv == 1):\n        epoch_list.append(epoch)\n        time_list.append(epoch_time)\n        train_lost_list.append(loss_train / len(train_loader))\n        train_acc_list.append(acc_train)\n        val_acc_list.append(acc_val)\n\n\n            \n            \n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:48.014990Z","iopub.execute_input":"2024-08-25T14:33:48.015246Z","iopub.status.idle":"2024-08-25T14:33:48.025305Z","shell.execute_reply.started":"2024-08-25T14:33:48.015224Z","shell.execute_reply":"2024-08-25T14:33:48.024350Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n\ndef validate(model, train_loader, val_loader):\n     model.eval()\n     for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n             correct = 0\n             total = 0\n             with torch.no_grad():\n                for imgs, labels in loader:\n                    imgs = imgs.to(device=device)\n                    labels = labels.to(device=device)\n                    model = model.to(device=device)\n                    outputs = model(imgs)\n                    _, predicted = torch.max(outputs, dim=1)\n                    total += labels.shape[0]\n                    correct += int((predicted == labels).sum())\n\n             print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n             if(name == \"train\"):\n                acc_train = correct / total\n             if(name == \"val\"):\n                acc_val = correct / total\n     return f\"{acc_train:.2f}\", f\"{acc_val:.2f}\" \n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:48.026475Z","iopub.execute_input":"2024-08-25T14:33:48.026749Z","iopub.status.idle":"2024-08-25T14:33:48.038659Z","shell.execute_reply.started":"2024-08-25T14:33:48.026727Z","shell.execute_reply":"2024-08-25T14:33:48.037910Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"inter_test = 1\ndump_csv = 1\ntraining_loop(n_epochs = 40, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_loader, \n                inter_test = inter_test, dump_csv = dump_csv)\n\nresults = {\n    \"Epoch\": epoch_list,\n    \"Time\": time_list,\n    \"Train_Accuracy\": train_acc_list,\n    \"Val_Accuracy\":val_acc_list\n}\n\ndf = pd.DataFrame(results)\ncsv_file = \"CNN_Width_results.csv\"\ndf.to_csv('/kaggle/working/DeepRsnt_results.csv', index=False)\n\nprint(f\"Training results successfully exported to csv\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:33:48.039703Z","iopub.execute_input":"2024-08-25T14:33:48.039940Z","iopub.status.idle":"2024-08-25T15:51:59.885301Z","shell.execute_reply.started":"2024-08-25T14:33:48.039920Z","shell.execute_reply":"2024-08-25T15:51:59.884276Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"48.45 Epoch 1, Training loss 0.8373139586220396\nAccuracy train: 0.75\nAccuracy val: 0.74\n184.47 Epoch 2, Training loss 0.47278600772644613\nAccuracy train: 0.77\nAccuracy val: 0.76\n300.21 Epoch 3, Training loss 0.4254218303459756\nAccuracy train: 0.82\nAccuracy val: 0.81\n418.03 Epoch 4, Training loss 0.37948159881411714\nAccuracy train: 0.83\nAccuracy val: 0.82\n536.38 Epoch 5, Training loss 0.35260819667514337\nAccuracy train: 0.86\nAccuracy val: 0.85\n655.00 Epoch 6, Training loss 0.33347507574139756\nAccuracy train: 0.84\nAccuracy val: 0.83\n772.11 Epoch 7, Training loss 0.32026555032489146\nAccuracy train: 0.86\nAccuracy val: 0.85\n889.03 Epoch 8, Training loss 0.3109186295657716\nAccuracy train: 0.86\nAccuracy val: 0.85\n1005.19 Epoch 9, Training loss 0.2969325399620736\nAccuracy train: 0.89\nAccuracy val: 0.88\n1120.44 Epoch 10, Training loss 0.2872200665321756\nAccuracy train: 0.88\nAccuracy val: 0.86\n1239.28 Epoch 11, Training loss 0.2768015183825442\nAccuracy train: 0.89\nAccuracy val: 0.87\n1357.12 Epoch 12, Training loss 0.2722119299021173\nAccuracy train: 0.89\nAccuracy val: 0.87\n1474.52 Epoch 13, Training loss 0.2626515544475393\nAccuracy train: 0.90\nAccuracy val: 0.89\n1593.32 Epoch 14, Training loss 0.2577805793348779\nAccuracy train: 0.87\nAccuracy val: 0.86\n1710.52 Epoch 15, Training loss 0.2516602528222064\nAccuracy train: 0.91\nAccuracy val: 0.89\n1827.45 Epoch 16, Training loss 0.24786340849513702\nAccuracy train: 0.90\nAccuracy val: 0.88\n1945.25 Epoch 17, Training loss 0.2398163054455468\nAccuracy train: 0.91\nAccuracy val: 0.90\n2060.74 Epoch 18, Training loss 0.2348928957622736\nAccuracy train: 0.86\nAccuracy val: 0.86\n2179.61 Epoch 19, Training loss 0.22913942985395166\nAccuracy train: 0.90\nAccuracy val: 0.88\n2295.78 Epoch 20, Training loss 0.2240067274170987\nAccuracy train: 0.88\nAccuracy val: 0.87\n2413.17 Epoch 21, Training loss 0.22182866166088175\nAccuracy train: 0.91\nAccuracy val: 0.89\n2532.02 Epoch 22, Training loss 0.21225495529460145\nAccuracy train: 0.87\nAccuracy val: 0.86\n2646.67 Epoch 23, Training loss 0.20632306046466878\nAccuracy train: 0.93\nAccuracy val: 0.91\n2765.67 Epoch 24, Training loss 0.20208284663076095\nAccuracy train: 0.91\nAccuracy val: 0.89\n2883.08 Epoch 25, Training loss 0.1973062312983452\nAccuracy train: 0.93\nAccuracy val: 0.91\n3000.71 Epoch 26, Training loss 0.1881732211864375\nAccuracy train: 0.89\nAccuracy val: 0.87\n3117.72 Epoch 27, Training loss 0.18390251200725424\nAccuracy train: 0.93\nAccuracy val: 0.91\n3235.37 Epoch 28, Training loss 0.1788251656404835\nAccuracy train: 0.93\nAccuracy val: 0.91\n3349.24 Epoch 29, Training loss 0.1729823723435402\nAccuracy train: 0.94\nAccuracy val: 0.91\n3466.49 Epoch 30, Training loss 0.16664158037685334\nAccuracy train: 0.94\nAccuracy val: 0.91\n3582.36 Epoch 31, Training loss 0.15865723871962822\nAccuracy train: 0.95\nAccuracy val: 0.92\n3697.53 Epoch 32, Training loss 0.15949112692094863\nAccuracy train: 0.93\nAccuracy val: 0.91\n3812.58 Epoch 33, Training loss 0.1491869286376428\nAccuracy train: 0.95\nAccuracy val: 0.92\n3929.30 Epoch 34, Training loss 0.14338358868151269\nAccuracy train: 0.91\nAccuracy val: 0.89\n4046.52 Epoch 35, Training loss 0.14052625806962557\nAccuracy train: 0.95\nAccuracy val: 0.92\n4160.22 Epoch 36, Training loss 0.13371188254987307\nAccuracy train: 0.91\nAccuracy val: 0.88\n4274.93 Epoch 37, Training loss 0.1288607999920211\nAccuracy train: 0.95\nAccuracy val: 0.92\n4389.07 Epoch 38, Training loss 0.12707587604985593\nAccuracy train: 0.95\nAccuracy val: 0.92\n4505.86 Epoch 39, Training loss 0.12256106799666552\nAccuracy train: 0.93\nAccuracy val: 0.90\n4620.12 Epoch 40, Training loss 0.11863309178659891\nAccuracy train: 0.93\nAccuracy val: 0.90\nTraining results successfully exported to csv\n","output_type":"stream"}]},{"cell_type":"code","source":"validate(model, train_loader, test_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:51:59.886828Z","iopub.execute_input":"2024-08-25T15:51:59.887136Z","iopub.status.idle":"2024-08-25T15:53:09.655201Z","shell.execute_reply.started":"2024-08-25T15:51:59.887104Z","shell.execute_reply":"2024-08-25T15:53:09.654061Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Accuracy train: 0.93\nAccuracy val: 0.90\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"('0.93', '0.90')"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv('/kaggle/working/DeepRsnt_results.csv', index=False)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:56:59.508852Z","iopub.execute_input":"2024-08-25T15:56:59.509491Z","iopub.status.idle":"2024-08-25T15:56:59.516084Z","shell.execute_reply.started":"2024-08-25T15:56:59.509456Z","shell.execute_reply":"2024-08-25T15:56:59.515162Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'Epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], 'Time': ['48.45', '184.47', '300.21', '418.03', '536.38', '655.00', '772.11', '889.03', '1005.19', '1120.44', '1239.28', '1357.12', '1474.52', '1593.32', '1710.52', '1827.45', '1945.25', '2060.74', '2179.61', '2295.78', '2413.17', '2532.02', '2646.67', '2765.67', '2883.08', '3000.71', '3117.72', '3235.37', '3349.24', '3466.49', '3582.36', '3697.53', '3812.58', '3929.30', '4046.52', '4160.22', '4274.93', '4389.07', '4505.86', '4620.12'], 'Train_Accuracy': ['0.75', '0.77', '0.82', '0.83', '0.86', '0.84', '0.86', '0.86', '0.89', '0.88', '0.89', '0.89', '0.90', '0.87', '0.91', '0.90', '0.91', '0.86', '0.90', '0.88', '0.91', '0.87', '0.93', '0.91', '0.93', '0.89', '0.93', '0.93', '0.94', '0.94', '0.95', '0.93', '0.95', '0.91', '0.95', '0.91', '0.95', '0.95', '0.93', '0.93'], 'Val_Accuracy': ['0.74', '0.76', '0.81', '0.82', '0.85', '0.83', '0.85', '0.85', '0.88', '0.86', '0.87', '0.87', '0.89', '0.86', '0.89', '0.88', '0.90', '0.86', '0.88', '0.87', '0.89', '0.86', '0.91', '0.89', '0.91', '0.87', '0.91', '0.91', '0.91', '0.91', '0.92', '0.91', '0.92', '0.89', '0.92', '0.88', '0.92', '0.92', '0.90', '0.90']}\n","output_type":"stream"}]},{"cell_type":"code","source":"#Accuracy train: 0.91\n#Accuracy val: 0.89\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:53:09.657107Z","iopub.execute_input":"2024-08-25T15:53:09.657524Z","iopub.status.idle":"2024-08-25T15:53:09.661558Z","shell.execute_reply.started":"2024-08-25T15:53:09.657472Z","shell.execute_reply":"2024-08-25T15:53:09.660735Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!lscpu","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:53:09.662717Z","iopub.execute_input":"2024-08-25T15:53:09.663041Z","iopub.status.idle":"2024-08-25T15:53:10.681370Z","shell.execute_reply.started":"2024-08-25T15:53:09.663011Z","shell.execute_reply":"2024-08-25T15:53:10.680445Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Architecture:                         x86_64\nCPU op-mode(s):                       32-bit, 64-bit\nByte Order:                           Little Endian\nAddress sizes:                        46 bits physical, 48 bits virtual\nCPU(s):                               4\nOn-line CPU(s) list:                  0-3\nThread(s) per core:                   2\nCore(s) per socket:                   2\nSocket(s):                            1\nNUMA node(s):                         1\nVendor ID:                            GenuineIntel\nCPU family:                           6\nModel:                                85\nModel name:                           Intel(R) Xeon(R) CPU @ 2.00GHz\nStepping:                             3\nCPU MHz:                              2000.160\nBogoMIPS:                             4000.32\nHypervisor vendor:                    KVM\nVirtualization type:                  full\nL1d cache:                            64 KiB\nL1i cache:                            64 KiB\nL2 cache:                             2 MiB\nL3 cache:                             38.5 MiB\nNUMA node0 CPU(s):                    0-3\nVulnerability Gather data sampling:   Not affected\nVulnerability Itlb multihit:          Not affected\nVulnerability L1tf:                   Mitigation; PTE Inversion\nVulnerability Mds:                    Mitigation; Clear CPU buffers; SMT Host st\n                                      ate unknown\nVulnerability Meltdown:               Mitigation; PTI\nVulnerability Mmio stale data:        Vulnerable: Clear CPU buffers attempted, n\n                                      o microcode; SMT Host state unknown\nVulnerability Reg file data sampling: Not affected\nVulnerability Retbleed:               Mitigation; IBRS\nVulnerability Spec rstack overflow:   Not affected\nVulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disab\n                                      led via prctl and seccomp\nVulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and _\n                                      _user pointer sanitization\nVulnerability Spectre v2:             Mitigation; IBRS; IBPB conditional; STIBP \n                                      conditional; RSB filling; PBRSB-eIBRS Not \n                                      affected; BHI SW loop, KVM SW loop\nVulnerability Srbds:                  Not affected\nVulnerability Tsx async abort:        Mitigation; Clear CPU buffers; SMT Host st\n                                      ate unknown\nFlags:                                fpu vme de pse tsc msr pae mce cx8 apic se\n                                      p mtrr pge mca cmov pat pse36 clflush mmx \n                                      fxsr sse sse2 ss ht syscall nx pdpe1gb rdt\n                                      scp lm constant_tsc rep_good nopl xtopolog\n                                      y nonstop_tsc cpuid tsc_known_freq pni pcl\n                                      mulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x\n                                      2apic movbe popcnt aes xsave avx f16c rdra\n                                      nd hypervisor lahf_lm abm 3dnowprefetch in\n                                      vpcid_single pti ssbd ibrs ibpb stibp fsgs\n                                      base tsc_adjust bmi1 hle avx2 smep bmi2 er\n                                      ms invpcid rtm mpx avx512f avx512dq rdseed\n                                       adx smap clflushopt clwb avx512cd avx512b\n                                      w avx512vl xsaveopt xsavec xgetbv1 xsaves \n                                      arat md_clear arch_capabilities\n","output_type":"stream"}]},{"cell_type":"code","source":"#torch.save(model.state_dict(), data_dir + 'Lung_cancer.pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:53:10.682822Z","iopub.execute_input":"2024-08-25T15:53:10.683133Z","iopub.status.idle":"2024-08-25T15:53:10.687373Z","shell.execute_reply.started":"2024-08-25T15:53:10.683101Z","shell.execute_reply":"2024-08-25T15:53:10.686552Z"},"trusted":true},"execution_count":16,"outputs":[]}]}